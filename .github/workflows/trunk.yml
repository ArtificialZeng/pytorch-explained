name: trunk

on:
  push:
    branches:
      - main
      - release/*
      - landchecks/*
    tags:
      - ciflow/trunk/*
  workflow_dispatch:
  schedule:
    - cron: 29 8 * * *  # about 1:29am PDT

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}
  cancel-in-progress: true

jobs:
  # Build PyTorch with BUILD_CAFFE2=ON
  caffe2-linux-focal-py3_8-gcc7-build:
    name: caffe2-linux-focal-py3.8-gcc7
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: caffe2-linux-focal-py3.8-gcc7
      docker-image-name: pytorch-linux-focal-py3.8-gcc7
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 1 },
        ]}

  linux-bionic-cuda12_1-py3_10-gcc9-build:
    name: linux-bionic-cuda12.1-py3.10-gcc9
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: linux-bionic-cuda12.1-py3.10-gcc9
      docker-image-name: pytorch-linux-bionic-cuda12.1-cudnn8-py3-gcc9
      test-matrix: |
        { include: [
          { config: "nogpu_AVX512", shard: 1, num_shards: 1, runner: "linux.2xlarge" },
          { config: "nogpu_NO_AVX2", shard: 1, num_shards: 1, runner: "linux.2xlarge" },
          { config: "jit_legacy", shard: 1, num_shards: 1, runner: "linux.4xlarge.nvidia.gpu" },
        ]}

  linux-bionic-cuda12_1-py3_10-gcc9-test:
    name: linux-bionic-cuda12.1-py3.10-gcc9
    uses: ./.github/workflows/_linux-test.yml
    needs: linux-bionic-cuda12_1-py3_10-gcc9-build
    with:
      build-environment: linux-bionic-cuda12.1-py3.10-gcc9
      docker-image: ${{ needs.linux-bionic-cuda12_1-py3_10-gcc9-build.outputs.docker-image }}
      test-matrix: ${{ needs.linux-bionic-cuda12_1-py3_10-gcc9-build.outputs.test-matrix }}

  libtorch-linux-bionic-cuda12_1-py3_7-gcc9-debug-build:
    name: libtorch-linux-bionic-cuda12.1-py3.7-gcc9-debug
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: libtorch-linux-bionic-cuda11.8-py3.7-gcc9
      docker-image-name: pytorch-linux-bionic-cuda11.8-cudnn8-py3-gcc9
      build-generates-artifacts: false
      runner: linux.2xlarge
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 1 },
        ]}

  # no-ops builds test USE_PER_OPERATOR_HEADERS=0 where ATen/ops is not generated
  linux-bionic-cuda12_1-py3_10-gcc9-no-ops-build:
    name: linux-bionic-cuda12.1-py3.10-gcc9-no-ops
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: linux-bionic-cuda12.1-py3.10-gcc9-no-ops
      docker-image-name: pytorch-linux-bionic-cuda12.1-cudnn8-py3-gcc9
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 1 },
        ]}

  pytorch-linux-focal-py3-clang7-android-ndk-r19c-build:
    name: pytorch-linux-focal-py3-clang7-android-ndk-r19c-build
    uses: ./.github/workflows/_android-full-build-test.yml
    with:
      build-environment: pytorch-linux-focal-py3-clang7-android-ndk-r19c-build
      docker-image-name: pytorch-linux-focal-py3-clang7-android-ndk-r19c
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 1, runner: "linux.2xlarge" },
        ]}

  macos-12-py3-arm64-build:
    name: macos-12-py3-arm64
    uses: ./.github/workflows/_mac-build.yml
    with:
      sync-tag: macos-12-py3-arm64-build
      build-environment: macos-12-py3-arm64
      runner-type: macos-m1-12
      build-generates-artifacts: true
      # To match the one pre-installed in the m1 runners
      python-version: 3.9.12
      # We need to set the environment file here instead of trying to detect it automatically because
      # MacOS arm64 is cross-compiled from x86-64. Specifically, it means that arm64 conda environment
      # is needed when building PyTorch MacOS arm64 from x86-64
      environment-file: .github/requirements/conda-env-macOS-ARM64
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 3, runner: "macos-m1-12" },
          { config: "default", shard: 2, num_shards: 3, runner: "macos-m1-12" },
          { config: "default", shard: 3, num_shards: 3, runner: "macos-m1-12" },
        ]}

  macos-12-py3-arm64-mps-test:
    name: macos-12-py3-arm64-mps
    uses: ./.github/workflows/_mac-test-mps.yml
    needs: macos-12-py3-arm64-build
    if: needs.macos-12-py3-arm64-build.outputs.build-outcome == 'success'
    with:
      sync-tag: macos-12-py3-arm64-mps-test
      build-environment: macos-12-py3-arm64
      # Same as the build job
      python-version: 3.9.12
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 1 },
        ]}

  macos-12-py3-arm64-test:
    name: macos-12-py3-arm64
    uses: ./.github/workflows/_mac-test.yml
    needs: macos-12-py3-arm64-build
    with:
      build-environment: macos-12-py3-arm64
      # Same as the build job
      python-version: 3.9.12
      test-matrix: ${{ needs.macos-12-py3-arm64-build.outputs.test-matrix }}
      arch: arm64

  win-vs2019-cpu-py3-build:
    name: win-vs2019-cpu-py3
    uses: ./.github/workflows/_win-build.yml
    with:
      build-environment: win-vs2019-cpu-py3
      cuda-version: cpu
      sync-tag: win-cpu-build
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 3, runner: "windows.4xlarge.nonephemeral" },
          { config: "default", shard: 2, num_shards: 3, runner: "windows.4xlarge.nonephemeral" },
          { config: "default", shard: 3, num_shards: 3, runner: "windows.4xlarge.nonephemeral" },
        ]}

  win-vs2019-cpu-py3-test:
    name: win-vs2019-cpu-py3
    uses: ./.github/workflows/_win-test.yml
    needs: win-vs2019-cpu-py3-build
    with:
      build-environment: win-vs2019-cpu-py3
      cuda-version: cpu
      test-matrix: ${{ needs.win-vs2019-cpu-py3-build.outputs.test-matrix }}

  win-vs2019-cuda11_8-py3-build:
    name: win-vs2019-cuda11.8-py3
    uses: ./.github/workflows/_win-build.yml
    with:
      build-environment: win-vs2019-cuda11.8-py3
      cuda-version: "11.8"
      sync-tag: win-cuda-build
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 6, runner: "windows.g5.4xlarge.nvidia.gpu" },
          { config: "default", shard: 2, num_shards: 6, runner: "windows.g5.4xlarge.nvidia.gpu" },
          { config: "default", shard: 3, num_shards: 6, runner: "windows.g5.4xlarge.nvidia.gpu" },
          { config: "default", shard: 4, num_shards: 6, runner: "windows.g5.4xlarge.nvidia.gpu" },
          { config: "default", shard: 5, num_shards: 6, runner: "windows.g5.4xlarge.nvidia.gpu" },
          { config: "default", shard: 6, num_shards: 6, runner: "windows.g5.4xlarge.nvidia.gpu" },
          { config: "force_on_cpu", shard: 1, num_shards: 1, runner: "windows.4xlarge.nonephemeral" },
        ]}

  linux-focal-rocm5_4_2-py3_8-build:
    name: linux-focal-rocm5.4.2-py3.8
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: linux-focal-rocm5.4.2-py3.8
      docker-image-name: pytorch-linux-focal-rocm-n-py3
      sync-tag: rocm-build
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 3, runner: "linux.rocm.gpu" },
          { config: "default", shard: 2, num_shards: 3, runner: "linux.rocm.gpu" },
          { config: "default", shard: 3, num_shards: 3, runner: "linux.rocm.gpu" },
        ]}

  linux-focal-rocm5_4_2-py3_8-test:
    name: linux-focal-rocm5.4.2-py3.8
    uses: ./.github/workflows/_rocm-test.yml
    needs: linux-focal-rocm5_4_2-py3_8-build
    with:
      build-environment: linux-focal-rocm5.4.2-py3.8
      docker-image: ${{ needs.linux-focal-rocm5_4_2-py3_8-build.outputs.docker-image }}
      test-matrix: ${{ needs.linux-focal-rocm5_4_2-py3_8-build.outputs.test-matrix }}
    secrets:
      AWS_OSSCI_METRICS_V2_ACCESS_KEY_ID: ${{ secrets.AWS_OSSCI_METRICS_V2_ACCESS_KEY_ID }}
      AWS_OSSCI_METRICS_V2_SECRET_ACCESS_KEY: ${{ secrets.AWS_OSSCI_METRICS_V2_SECRET_ACCESS_KEY }}
